{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "563b3958-a98f-4a5e-94f9-3a047a7145b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import yaml\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import albumentations as A\n",
    "import matplotlib.pyplot as plt\n",
    "import io\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb324f7f-eda4-4b38-9ef0-86e9d45c08c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install efficientnet-pytorch\n",
    "# !pip install albumentations==1.1.0\n",
    "# !pip install numpy==1.24.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0177676f-c9d2-4aec-881f-12a78d8f1bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models import SiamNet, get_siamnet, get_transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "405d0df9-7c57-4271-b3f9-d4eb822c564d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform = Transform()\n",
    "\n",
    "# config_path = 'configs/finetuning_config.yaml'\n",
    "config_path = 'configs/train_config.yaml'\n",
    "\n",
    "with open(config_path, 'r') as file:\n",
    "    train_config = yaml.safe_load(file)\n",
    "    # finetuning_config = yaml.safe_load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d39f68d-6bb2-4d23-a390-4e6517537538",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b3\n",
      "loaded weights from /mnt/DATA2/dorin/res.cv.science.is.matching/effnet_tuning/checkpoints/SiamNet_tunehead_600.pth\n"
     ]
    }
   ],
   "source": [
    "net = get_siamnet(train_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3da99654-b4cc-4aac-a87a-174fa54b2f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class CustomDataset(Dataset):\n",
    "#     def __init__(self, json_file):\n",
    "#         with open(json_file, 'r') as f:\n",
    "#             self.data = json.load(f)\n",
    "#         self.basic_transform, self.simple_transform, self.train_transform = get_transforms()\n",
    "#         self.image_paths = []\n",
    "\n",
    "#         for images in self.data.values():\n",
    "#             for img_path in images:\n",
    "#                 self.image_paths.append(img_path)\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.image_paths)\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         image_path = self.image_paths[idx]\n",
    "#         image = Image.open(image_path).convert('RGB')\n",
    "\n",
    "#         # Apply the first transformation\n",
    "#         augmented1 = self.train_transform(image).convert('RGB')\n",
    "#         # augmented1.show()\n",
    "\n",
    "#         # Apply the second transformation\n",
    "#         augmented2 = self.simple_transform(image).convert('RGB')\n",
    "#         # augmented2.show()\n",
    "        \n",
    "#         tensor1 = self.basic_transform(augmented1)\n",
    "#         tensor2 = self.basic_transform(augmented2)\n",
    "\n",
    "#         return tensor1, tensor2\n",
    "\n",
    "\n",
    "\n",
    "# json_file = '../notebooks/data/thur/thur_dataset.json'\n",
    "\n",
    "# full_dataset = CustomDataset(json_file)\n",
    "\n",
    "# train_size = int(0.8 * len(full_dataset))\n",
    "# test_size = len(full_dataset) - train_size\n",
    "# train_indices, test_indices = train_test_split(list(range(len(full_dataset))),\n",
    "#                                                test_size=test_size,\n",
    "#                                                random_state=42)\n",
    "\n",
    "# train_dataset = Subset(full_dataset, train_indices)\n",
    "# test_dataset = Subset(full_dataset, test_indices)\n",
    "\n",
    "# train_loader = DataLoader(train_dataset, batch_size=train_config['training']['batch_size'], shuffle=True, num_workers=0)\n",
    "# test_loader = DataLoader(test_dataset, batch_size=train_config['training']['batch_size'], shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4419561-e968-42a4-9e7e-0fa52478620f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchvision import transforms\n",
    "\n",
    "class CombinedDataset(Dataset):\n",
    "    def __init__(self, data_dir):\n",
    "        self.basic_transform, self.simple_transform, self.train_transform = get_transforms()\n",
    "        self.data_dir = data_dir\n",
    "        # self.transform = transform\n",
    "        self.image_paths = []\n",
    "        self.coco_paths = []\n",
    "        self.thur_paths = []\n",
    "        self.landscapes_paths = []\n",
    "\n",
    "        # Сбор путей к изображениям для COCO 2017\n",
    "        coco_dir = os.path.join(data_dir, 'coco2017', 'coco_images')\n",
    "        for split in ['test2017', 'train2017', 'unlabeled2017', 'val2017']:\n",
    "            split_dir = os.path.join(coco_dir, split)\n",
    "            for root, _, files in os.walk(split_dir):\n",
    "                for file in files:\n",
    "                    if file.endswith(('.jpg', '.png', '.jpeg')):\n",
    "                        self.coco_paths.append(os.path.join(root, file))\n",
    "\n",
    "        # Сбор путей к изображениям для THUR15000\n",
    "        thur_dir = os.path.join(data_dir, 'thur', 'THUR15000')\n",
    "        for category in os.listdir(thur_dir):\n",
    "            category_dir = os.path.join(thur_dir, category, 'Src')\n",
    "            if os.path.isdir(category_dir):\n",
    "                for file in os.listdir(category_dir):\n",
    "                    if file.endswith(('.jpg', '.png', '.jpeg')):\n",
    "                        self.thur_paths.append(os.path.join(category_dir, file))\n",
    "\n",
    "        # Сбор путей к изображениям для landscapes\n",
    "        landscapes_dir = os.path.join(data_dir, 'landscapes')\n",
    "        for root, _, files in os.walk(landscapes_dir):\n",
    "            for file in files:\n",
    "                if file.endswith(('.jpg', '.png', '.jpeg')):\n",
    "                    self.landscapes_paths.append(os.path.join(root, file))\n",
    "\n",
    "        # Combine all paths\n",
    "        self.image_paths = self.coco_paths + self.thur_paths + self.landscapes_paths\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.image_paths[idx]\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "\n",
    "        # Apply the first transformation\n",
    "        augmented1 = self.train_transform(image).convert('RGB')\n",
    "\n",
    "        # Apply the second transformation\n",
    "        augmented2 = self.simple_transform(image).convert('RGB')\n",
    "\n",
    "        tensor1 = self.basic_transform(augmented1)\n",
    "        tensor2 = self.basic_transform(augmented2)\n",
    "        \n",
    "        return tensor1, tensor2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d79929c7-000d-449d-be5d-57223dacf3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../notebooks/data'\n",
    "\n",
    "full_dataset = CombinedDataset(data_dir)\n",
    "\n",
    "# Split each dataset separately\n",
    "coco_train_indices, coco_test_indices = train_test_split(\n",
    "    list(range(len(full_dataset.coco_paths))), test_size=0.05, random_state=42)\n",
    "thur_train_indices, thur_test_indices = train_test_split(\n",
    "    list(range(len(full_dataset.thur_paths))), test_size=0.05, random_state=42)\n",
    "landscapes_train_indices, landscapes_test_indices = train_test_split(\n",
    "    list(range(len(full_dataset.landscapes_paths))), test_size=0.05, random_state=42)\n",
    "\n",
    "# Combine the indices\n",
    "train_indices = coco_train_indices + thur_train_indices + landscapes_train_indices\n",
    "test_indices = coco_test_indices + thur_test_indices + landscapes_test_indices\n",
    "\n",
    "# Create subsets\n",
    "train_dataset = Subset(full_dataset, train_indices)\n",
    "test_dataset = Subset(full_dataset, test_indices)\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=train_config['training']['batch_size'], shuffle=True, num_workers=0)\n",
    "test_loader = DataLoader(test_dataset, batch_size=train_config['training']['batch_size'], shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3c876c73-a3a5-4557-9689-7747167770c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from train import train_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6487db73-cd0d-4fa8-bd47-a2f3458a3143",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9121/9121 [4:49:38<00:00,  1.91s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/300], Train Loss: 0.0006,               Train Accuracy: 0.9839, Train F1: 0.6521, Train Recall: 0.4838,               Train Precision: 0.9999, Val Loss: 0.0452,               lr: 0.0001,               Val Accuracy: 0.9788, Val F1: 0.4879, Val Recall: 0.3227,               Val Precision: 1.0000\n",
      "Checkpoint saved at epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9121/9121 [4:56:21<00:00,  1.95s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/300], Train Loss: 0.0003,               Train Accuracy: 0.9766, Train F1: 0.4028, Train Recall: 0.2522,               Train Precision: 1.0000, Val Loss: 0.0507,               lr: 5e-05,               Val Accuracy: 0.9763, Val F1: 0.3891, Val Recall: 0.2415,               Val Precision: 1.0000\n",
      "Checkpoint saved at epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9121/9121 [4:57:38<00:00,  1.96s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/300], Train Loss: 0.0001,               Train Accuracy: 0.9766, Train F1: 0.3997, Train Recall: 0.2497,               Train Precision: 1.0000, Val Loss: 0.0501,               lr: 5e-05,               Val Accuracy: 0.9768, Val F1: 0.4107, Val Recall: 0.2584,               Val Precision: 1.0000\n",
      "Checkpoint saved at epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9121/9121 [5:01:11<00:00,  1.98s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/300], Train Loss: 0.0001,               Train Accuracy: 0.9769, Train F1: 0.4125, Train Recall: 0.2599,               Train Precision: 1.0000, Val Loss: 0.0503,               lr: 2.5e-05,               Val Accuracy: 0.9770, Val F1: 0.4162, Val Recall: 0.2628,               Val Precision: 1.0000\n",
      "Checkpoint saved at epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9121/9121 [5:00:05<00:00,  1.97s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/300], Train Loss: 0.0001,               Train Accuracy: 0.9776, Train F1: 0.4404, Train Recall: 0.2823,               Train Precision: 1.0000, Val Loss: 0.0430,               lr: 1.25e-05,               Val Accuracy: 0.9787, Val F1: 0.4842, Val Recall: 0.3194,               Val Precision: 1.0000\n",
      "Checkpoint saved at epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9121/9121 [4:57:42<00:00,  1.96s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/300], Train Loss: 0.0000,               Train Accuracy: 0.9789, Train F1: 0.4919, Train Recall: 0.3261,               Train Precision: 1.0000, Val Loss: 0.0408,               lr: 1.25e-05,               Val Accuracy: 0.9789, Val F1: 0.4895, Val Recall: 0.3241,               Val Precision: 1.0000\n",
      "Checkpoint saved at epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9121/9121 [4:57:37<00:00,  1.96s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/300], Train Loss: 0.0001,               Train Accuracy: 0.9802, Train F1: 0.5351, Train Recall: 0.3653,               Train Precision: 1.0000, Val Loss: 0.0312,               lr: 1.25e-05,               Val Accuracy: 0.9818, Val F1: 0.5892, Val Recall: 0.4176,               Val Precision: 1.0000\n",
      "Checkpoint saved at epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9121/9121 [4:59:31<00:00,  1.97s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/300], Train Loss: 0.0000,               Train Accuracy: 0.9807, Train F1: 0.5521, Train Recall: 0.3813,               Train Precision: 1.0000, Val Loss: 0.0319,               lr: 1.25e-05,               Val Accuracy: 0.9813, Val F1: 0.5735, Val Recall: 0.4020,               Val Precision: 1.0000\n",
      "Checkpoint saved at epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9121/9121 [5:01:13<00:00,  1.98s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/300], Train Loss: 0.0001,               Train Accuracy: 0.9814, Train F1: 0.5768, Train Recall: 0.4052,               Train Precision: 1.0000, Val Loss: 0.0338,               lr: 1.25e-05,               Val Accuracy: 0.9813, Val F1: 0.5746, Val Recall: 0.4031,               Val Precision: 1.0000\n",
      "Checkpoint saved at epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 21/9121 [00:38<4:17:40,  1.70s/it]"
     ]
    }
   ],
   "source": [
    "train_model(net, train_loader, test_loader, train_config, resume=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff27219-3b43-4f34-ba2b-47c9255e98b0",
   "metadata": {},
   "source": [
    "### Тюнинг модельки на big data\n",
    "\n",
    "\n",
    "Epoch [1/300], Train Loss: 0.0034,               Train Accuracy: 0.9897, Train F1: 0.8034, Train Recall: 0.6715,               Train Precision: 0.9998, Val Loss: 0.0082,               lr: 5e-05,               Val Accuracy: 0.9903, Val F1: 0.8170, Val Recall: 0.6908,               Val Precision: 0.9994\n",
    "Checkpoint saved at epoch 1\n",
    "100%|██████████| 9121/9121 [4:50:44<00:00,  1.91s/it]   \n",
    "Epoch [2/300], Train Loss: 0.0027,               Train Accuracy: 0.9919, Train F1: 0.8516, Train Recall: 0.7423,               Train Precision: 0.9988, Val Loss: 0.0061,               lr: 2.5e-05,               Val Accuracy: 0.9927, Val F1: 0.8670, Val Recall: 0.7660,               Val Precision: 0.9986\n",
    "Checkpoint saved at epoch 2\n",
    "100%|██████████| 9121/9121 [4:50:38<00:00,  1.91s/it]   \n",
    "Epoch [3/300], Train Loss: 0.0022,               Train Accuracy: 0.9933, Train F1: 0.8809, Train Recall: 0.7890,               Train Precision: 0.9970, Val Loss: 0.0050,               lr: 2.5e-05,               Val Accuracy: 0.9939, Val F1: 0.8920, Val Recall: 0.8078,               Val Precision: 0.9957\n",
    "Checkpoint saved at epoch 3\n",
    "100%|██████████| 9121/9121 [4:56:18<00:00,  1.95s/it]   \n",
    "Epoch [4/300], Train Loss: 0.0022,               Train Accuracy: 0.9942, Train F1: 0.8990, Train Recall: 0.8198,               Train Precision: 0.9952, Val Loss: 0.0048,               lr: 1.25e-05,               Val Accuracy: 0.9942, Val F1: 0.8992, Val Recall: 0.8207,               Val Precision: 0.9942\n",
    "Checkpoint saved at epoch 4\n",
    "100%|██████████| 9121/9121 [4:57:33<00:00,  1.96s/it]  \n",
    "Epoch [5/300], Train Loss: 0.0020,               Train Accuracy: 0.9949, Train F1: 0.9112, Train Recall: 0.8419,               Train Precision: 0.9930, Val Loss: 0.0045,               lr: 1.25e-05,               Val Accuracy: 0.9945, Val F1: 0.9037, Val Recall: 0.8279,               Val Precision: 0.9948\n",
    "Checkpoint saved at epoch 5\n",
    "100%|██████████| 9121/9121 [4:36:38<00:00,  1.82s/it]  \n",
    "Epoch [6/300], Train Loss: 0.0020,               Train Accuracy: 0.9952, Train F1: 0.9176, Train Recall: 0.8533,               Train Precision: 0.9923, Val Loss: 0.0039,               lr: 1.25e-05,               Val Accuracy: 0.9959, Val F1: 0.9307, Val Recall: 0.8791,               Val Precision: 0.9887\n",
    "Checkpoint saved at epoch 6\n",
    "100%|██████████| 9121/9121 [4:33:00<00:00,  1.80s/it]  \n",
    "Epoch [7/300], Train Loss: 0.0020,               Train Accuracy: 0.9955, Train F1: 0.9227, Train Recall: 0.8627,               Train Precision: 0.9917, Val Loss: 0.0038,               lr: 1.25e-05,               Val Accuracy: 0.9959, Val F1: 0.9313, Val Recall: 0.8794,               Val Precision: 0.9896\n",
    "Checkpoint saved at epoch 7\n",
    "100%|██████████| 9121/9121 [4:30:48<00:00,  1.78s/it]  \n",
    "Epoch [8/300], Train Loss: 0.0020,               Train Accuracy: 0.9959, Train F1: 0.9309, Train Recall: 0.8799,               Train Precision: 0.9881, Val Loss: 0.0038,               lr: 1.25e-05,               Val Accuracy: 0.9964, Val F1: 0.9395, Val Recall: 0.9011,               Val Precision: 0.9812\n",
    "Checkpoint saved at epoch 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "975901a0-6c85-4a07-a61a-760ced6d3e04",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
